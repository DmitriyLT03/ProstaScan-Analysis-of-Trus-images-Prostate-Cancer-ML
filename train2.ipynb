{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from torchmetrics import JaccardIndex\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CustomDataset import load_data\n",
    "from utils.loss import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = load_data(test_size=0.3, batch_size=1, img_size=256, dir='./data/all_data/', artificial_increase=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = JaccardIndex(task='binary',num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=1, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = JaccardLoss().to(device)\n",
    "# criterion_val = JaccardLoss(log_loss=True).to(device)\n",
    "criterion = DiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_jaccard_score(\n",
    "    output: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    smooth: float = 0.0,\n",
    "    eps: float = 1e-7,\n",
    "\n",
    ") -> torch.Tensor:\n",
    "    intersection = torch.sum(output * target)\n",
    "    cardinality = torch.sum(output + target)\n",
    "\n",
    "    union = cardinality - intersection\n",
    "    jaccard_score = (intersection + smooth) / (union + smooth).clamp_min(eps)\n",
    "    return jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    score = 0\n",
    "\n",
    "    # iterate over the validation set\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc= f'Validation', unit='batch', leave=False):\n",
    "        image, mask_true = batch['image'], batch['mask']\n",
    "\n",
    "        image = image.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "        mask_true = mask_true.to(device=device, dtype=torch.long)\n",
    "\n",
    "        mask_pred = model(image)\n",
    "            \n",
    "        iou_curr = soft_jaccard_score(mask_true.cpu(), mask_pred.cpu())\n",
    "        score += iou_curr\n",
    "            \n",
    "            \n",
    "\n",
    "    return iou_curr / max(len(dataloader), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    device,\n",
    "    criterion, \n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs: int=10,\n",
    "    learning_rate: float=1e-5,\n",
    "    img_scale: float=0.5, \n",
    "):\n",
    "    model.train()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "    # criterion = JaccardLoss().to(device)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_score = 0\n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch}/{epochs}', unit='img') as epoch_bar:\n",
    "            for batch in train_loader:\n",
    "                images, mask = batch['image'], batch['mask']\n",
    "                images = images.to(device, dtype=torch.float32)\n",
    "                mask = mask.to(device, dtype=torch.long)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                output = model(images)\n",
    "                loss = criterion(output.squeeze(1), mask.squeeze(1).float())\n",
    "                    \n",
    "                loss.backward()\n",
    "                # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                # grad_scaler.step(optimizer)\n",
    "                # grad_scaler.update()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                epoch_bar.update()\n",
    "            \n",
    "                iou_curr = soft_jaccard_score(mask.cpu(), output.cpu())\n",
    "                train_score += iou_curr\n",
    "                \n",
    "                epoch_bar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "                \n",
    "        model.eval()\n",
    "        val_score = evaluate(model, val_loader, device)\n",
    "        print(f'Train {epoch} epoch with iou-score:{train_score/len(train_loader)}')\n",
    "        print(f'Valid {epoch} epoch with iou-score:{val_score}')\n",
    "        scheduler.step(val_score)\n",
    "        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 266/266 [00:11<00:00, 24.13img/s, loss (batch)=0.00397]\n",
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1 epoch with iou-score:0.007801605388522148\n",
      "Valid 1 epoch with iou-score:7.312961315619759e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 266/266 [00:08<00:00, 30.02img/s, loss (batch)=0.00089]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 2 epoch with iou-score:0.007533056195825338\n",
      "Valid 2 epoch with iou-score:7.27738051864435e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 266/266 [00:08<00:00, 30.18img/s, loss (batch)=0.000624]\n",
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 3 epoch with iou-score:0.00750366086140275\n",
      "Valid 3 epoch with iou-score:7.22636877981131e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 266/266 [00:08<00:00, 30.23img/s, loss (batch)=0.000439]\n",
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 4 epoch with iou-score:0.0074931420385837555\n",
      "Valid 4 epoch with iou-score:7.2292609729629476e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 266/266 [00:08<00:00, 30.66img/s, loss (batch)=0.000284]\n",
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 5 epoch with iou-score:0.00749823497608304\n",
      "Valid 5 epoch with iou-score:7.277587428689003e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 266/266 [00:08<00:00, 30.37img/s, loss (batch)=0.000203]\n",
      "                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(model, device, criterion, train_loader, valid_loader)\n",
      "Cell \u001b[1;32mIn[10], line 48\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, device, criterion, train_loader, val_loader, epochs, learning_rate, img_scale)\u001b[0m\n\u001b[0;32m     45\u001b[0m         epoch_bar\u001b[39m.\u001b[39mset_postfix(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mloss (batch)\u001b[39m\u001b[39m'\u001b[39m: loss\u001b[39m.\u001b[39mitem()})\n\u001b[0;32m     47\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> 48\u001b[0m val_score \u001b[39m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[0;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m epoch with iou-score:\u001b[39m\u001b[39m{\u001b[39;00mtrain_score\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_loader)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValid \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m epoch with iou-score:\u001b[39m\u001b[39m{\u001b[39;00mval_score\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dmitry\\Desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataloader, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m score \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39m# iterate over the validation set\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(dataloader, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataloader), desc\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m'\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m     image, mask_true \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m], batch[\u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m     image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mchannels_last)\n",
      "File \u001b[1;32mc:\\Users\\Dmitry\\Desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dmitry\\Desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:444\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\Dmitry\\Desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:390\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    389\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Dmitry\\Desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1077\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1070\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1077\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1078\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1079\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, device, criterion, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_trus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4af9a2159fab24886d4f91335261a63555b0395985130eb8d259fcbaf5c78d65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
