{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: Skipping segmentation-models-pytorch as it is not installed.\n"]}],"source":["!pip uninstall -y segmentation-models-pytorch"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:32:37.550588Z","iopub.status.busy":"2023-01-30T17:32:37.549798Z","iopub.status.idle":"2023-01-30T17:32:57.149293Z","shell.execute_reply":"2023-01-30T17:32:57.148081Z","shell.execute_reply.started":"2023-01-30T17:32:37.550162Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (4.7.0.68)\n","Requirement already satisfied: numpy>=1.19.3 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from opencv-python) (1.24.1)\n","Requirement already satisfied: opencv-contrib-python in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (4.7.0.68)\n","Requirement already satisfied: numpy>=1.17.0 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from opencv-contrib-python) (1.24.1)\n"]}],"source":["!pip install opencv-python\n","!pip install opencv-contrib-python"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:32:57.152119Z","iopub.status.busy":"2023-01-30T17:32:57.151804Z","iopub.status.idle":"2023-01-30T17:33:08.844932Z","shell.execute_reply":"2023-01-30T17:33:08.843425Z","shell.execute_reply.started":"2023-01-30T17:32:57.152073Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: imutils in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (0.5.4)\n"]}],"source":["!pip install imutils"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:08.848381Z","iopub.status.busy":"2023-01-30T17:33:08.846733Z","iopub.status.idle":"2023-01-30T17:33:22.303882Z","shell.execute_reply":"2023-01-30T17:33:22.302644Z","shell.execute_reply.started":"2023-01-30T17:33:08.848338Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting segmentation-models-pytorch\n","  Using cached segmentation_models_pytorch-0.3.2-py3-none-any.whl (106 kB)\n","Requirement already satisfied: albumentations in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (1.3.0)\n","Requirement already satisfied: torchvision>=0.5.0 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from segmentation-models-pytorch) (0.13.1+cu116)\n","Requirement already satisfied: efficientnet-pytorch==0.7.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from segmentation-models-pytorch) (0.7.1)\n","Requirement already satisfied: timm==0.6.12 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from segmentation-models-pytorch) (0.6.12)\n","Requirement already satisfied: pillow in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from segmentation-models-pytorch) (9.4.0)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from segmentation-models-pytorch) (0.7.4)\n","Requirement already satisfied: tqdm in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from segmentation-models-pytorch) (4.64.1)\n","Requirement already satisfied: torch in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12.1+cu116)\n","Requirement already satisfied: munch in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\n","Requirement already satisfied: pyyaml in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from timm==0.6.12->segmentation-models-pytorch) (6.0)\n","Requirement already satisfied: huggingface-hub in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from timm==0.6.12->segmentation-models-pytorch) (0.12.0)\n","Requirement already satisfied: qudida>=0.0.4 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from albumentations) (0.0.4)\n","Requirement already satisfied: scipy in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from albumentations) (1.10.0)\n","Requirement already satisfied: numpy>=1.11.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from albumentations) (1.24.1)\n","Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from albumentations) (4.7.0.68)\n","Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from albumentations) (0.19.3)\n","Requirement already satisfied: typing-extensions in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n","Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.2.1)\n","Requirement already satisfied: networkx>=2.2 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n","Requirement already satisfied: imageio>=2.4.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.25.0)\n","Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (23.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2023.1.23.1)\n","Requirement already satisfied: requests in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.28.2)\n","Requirement already satisfied: colorama in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from tqdm->segmentation-models-pytorch) (0.4.6)\n","Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n","Requirement already satisfied: filelock in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (3.9.0)\n","Requirement already satisfied: six in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.0.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\n","Installing collected packages: segmentation-models-pytorch\n","Successfully installed segmentation-models-pytorch-0.3.2\n"]}],"source":["!pip install -U segmentation-models-pytorch albumentations"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:22.307867Z","iopub.status.busy":"2023-01-30T17:33:22.307176Z","iopub.status.idle":"2023-01-30T17:33:32.050633Z","shell.execute_reply":"2023-01-30T17:33:32.049439Z","shell.execute_reply.started":"2023-01-30T17:33:22.307821Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ttach in c:\\users\\dmitry\\desktop\\code\\analysis_trus_images\\env_trus\\lib\\site-packages (0.0.3)\n"]}],"source":["!pip install ttach"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:32.054666Z","iopub.status.busy":"2023-01-30T17:33:32.054348Z","iopub.status.idle":"2023-01-30T17:33:33.857379Z","shell.execute_reply":"2023-01-30T17:33:33.856371Z","shell.execute_reply.started":"2023-01-30T17:33:32.054635Z"},"trusted":true},"outputs":[],"source":["import ttach as tta"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:33.865597Z","iopub.status.busy":"2023-01-30T17:33:33.861838Z","iopub.status.idle":"2023-01-30T17:33:34.062028Z","shell.execute_reply":"2023-01-30T17:33:34.060819Z","shell.execute_reply.started":"2023-01-30T17:33:33.865558Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from PIL import Image"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:34.076447Z","iopub.status.busy":"2023-01-30T17:33:34.068680Z","iopub.status.idle":"2023-01-30T17:33:34.115481Z","shell.execute_reply":"2023-01-30T17:33:34.111561Z","shell.execute_reply.started":"2023-01-30T17:33:34.076400Z"},"trusted":true},"outputs":[],"source":["list_images = os.listdir('./all_data/images')\n","list_masks = os.listdir('./all_data/masks')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:34.116870Z","iopub.status.busy":"2023-01-30T17:33:34.116531Z","iopub.status.idle":"2023-01-30T17:33:34.141472Z","shell.execute_reply":"2023-01-30T17:33:34.127149Z","shell.execute_reply.started":"2023-01-30T17:33:34.116833Z"},"trusted":true},"outputs":[],"source":["IMG_SIZE = 256"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:34.143693Z","iopub.status.busy":"2023-01-30T17:33:34.142849Z","iopub.status.idle":"2023-01-30T17:33:35.737146Z","shell.execute_reply":"2023-01-30T17:33:35.736142Z","shell.execute_reply.started":"2023-01-30T17:33:34.143654Z"},"trusted":true},"outputs":[],"source":["array_of_images = []\n","array_of_masks = []\n","for name_image, name_mask in zip(list_images, list_masks):\n","\n","    image = cv2.imread(f'./all_data/images/{name_image}')\n","    image = np.array(Image.fromarray(image).resize((IMG_SIZE, IMG_SIZE))).astype('float32')/255\n","    \n","    img = (image - np.mean(image))/np.std(image)\n","\n","    img_gray = 0.299*img[:,:,0] + 0.587*img[:,:,1] + 0.114*img[:,:,2]\n","    img_gray = np.moveaxis(img_gray, -1, 0)\n","    \n","    mask = cv2.imread(f'./all_data/masks/{name_mask}')*255\n","    mask = np.array(Image.fromarray(mask).resize((IMG_SIZE, IMG_SIZE))).astype('float32')\n","    mask = mask.max(axis=2)/255\n","#     mask = np.array([mask])\n","    \n","    #Extract our images\n","    array_of_images.append(img_gray)\n","    array_of_masks.append(mask)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:35.741466Z","iopub.status.busy":"2023-01-30T17:33:35.741141Z","iopub.status.idle":"2023-01-30T17:33:35.745708Z","shell.execute_reply":"2023-01-30T17:33:35.744764Z","shell.execute_reply.started":"2023-01-30T17:33:35.741439Z"},"trusted":true},"outputs":[],"source":["array_of_images*=100\n","array_of_masks*=100"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:35.747770Z","iopub.status.busy":"2023-01-30T17:33:35.747180Z","iopub.status.idle":"2023-01-30T17:33:35.755725Z","shell.execute_reply":"2023-01-30T17:33:35.754762Z","shell.execute_reply.started":"2023-01-30T17:33:35.747732Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:35.757548Z","iopub.status.busy":"2023-01-30T17:33:35.757210Z","iopub.status.idle":"2023-01-30T17:33:37.002555Z","shell.execute_reply":"2023-01-30T17:33:37.001575Z","shell.execute_reply.started":"2023-01-30T17:33:35.757515Z"},"trusted":true},"outputs":[],"source":["import albumentations as albu"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:37.004409Z","iopub.status.busy":"2023-01-30T17:33:37.004039Z","iopub.status.idle":"2023-01-30T17:33:37.010149Z","shell.execute_reply":"2023-01-30T17:33:37.009018Z","shell.execute_reply.started":"2023-01-30T17:33:37.004368Z"},"trusted":true},"outputs":[],"source":["def get_training_augmentation():\n","    train_transform = [\n","        \n","        albu.RandomCrop(width = IMG_SIZE, height = IMG_SIZE),\n","        albu.RandomRotate90(),\n","        albu.Flip(p=0.5),\n","#         albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n","    ]\n","    return albu.Compose(train_transform)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:37.012187Z","iopub.status.busy":"2023-01-30T17:33:37.011597Z","iopub.status.idle":"2023-01-30T17:33:37.021260Z","shell.execute_reply":"2023-01-30T17:33:37.020344Z","shell.execute_reply.started":"2023-01-30T17:33:37.012144Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:37.023327Z","iopub.status.busy":"2023-01-30T17:33:37.022863Z","iopub.status.idle":"2023-01-30T17:33:37.033992Z","shell.execute_reply":"2023-01-30T17:33:37.033049Z","shell.execute_reply.started":"2023-01-30T17:33:37.023196Z"},"trusted":true},"outputs":[],"source":["class Dataset(BaseDataset):\n","    def __init__(\n","            self, \n","            images, \n","            masks, \n","            augmentation=None\n","    ):\n","        self.images = images\n","        self.masks = masks\n","        self.augmentation = augmentation\n","    \n","    def __getitem__(self, i):\n","        image = self.images[i]\n","        mask = self.masks[i]\n","        # apply augmentations\n","        flag = np.random.rand() > 0.3\n","        \n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            img, small_mask = sample['image'], sample['mask']\n","            while small_mask.sum() == 0 and flag:\n","                sample = self.augmentation(image=image, mask=mask)\n","                img, small_mask = sample['image'], sample['mask']\n","        \n","        \n","        return torch.tensor(np.array([img]), dtype = torch.float), torch.tensor(np.array([small_mask]), dtype = torch.float)\n","        \n","    def __len__(self):\n","        return len(self.images)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:37.035755Z","iopub.status.busy":"2023-01-30T17:33:37.035400Z","iopub.status.idle":"2023-01-30T17:33:39.490583Z","shell.execute_reply":"2023-01-30T17:33:39.489505Z","shell.execute_reply.started":"2023-01-30T17:33:37.035718Z"},"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch import utils"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:39.492291Z","iopub.status.busy":"2023-01-30T17:33:39.491901Z","iopub.status.idle":"2023-01-30T17:33:45.284858Z","shell.execute_reply":"2023-01-30T17:33:45.283825Z","shell.execute_reply.started":"2023-01-30T17:33:39.492255Z"},"trusted":true},"outputs":[{"data":{"text/plain":["FPN(\n","  (encoder): ResNetEncoder(\n","    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (decoder): FPNDecoder(\n","    (p5): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (p4): FPNBlock(\n","      (skip_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (p3): FPNBlock(\n","      (skip_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (p2): FPNBlock(\n","      (skip_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (seg_blocks): ModuleList(\n","      (0): SegmentationBlock(\n","        (block): Sequential(\n","          (0): Conv3x3GNReLU(\n","            (block): Sequential(\n","              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","              (2): ReLU(inplace=True)\n","            )\n","          )\n","          (1): Conv3x3GNReLU(\n","            (block): Sequential(\n","              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","              (2): ReLU(inplace=True)\n","            )\n","          )\n","          (2): Conv3x3GNReLU(\n","            (block): Sequential(\n","              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","              (2): ReLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (1): SegmentationBlock(\n","        (block): Sequential(\n","          (0): Conv3x3GNReLU(\n","            (block): Sequential(\n","              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","              (2): ReLU(inplace=True)\n","            )\n","          )\n","          (1): Conv3x3GNReLU(\n","            (block): Sequential(\n","              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","              (2): ReLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (2): SegmentationBlock(\n","        (block): Sequential(\n","          (0): Conv3x3GNReLU(\n","            (block): Sequential(\n","              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","              (2): ReLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (3): SegmentationBlock(\n","        (block): Sequential(\n","          (0): Conv3x3GNReLU(\n","            (block): Sequential(\n","              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","              (2): ReLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (merge): MergeBlock()\n","    (dropout): Dropout2d(p=0.2, inplace=True)\n","  )\n","  (segmentation_head): SegmentationHead(\n","    (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n","    (1): UpsamplingBilinear2d(scale_factor=4.0, mode=bilinear)\n","    (2): Activation(\n","      (activation): Sigmoid()\n","    )\n","  )\n",")"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["ENCODER = 'resnet34'\n","ENCODER_WEIGHTS = 'imagenet'\n","ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n","DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu') \n","\n","# create segmentation model with pretrained encoder\n","model = smp.FPN(\n","    encoder_name=ENCODER, \n","    encoder_weights=ENCODER_WEIGHTS,\n","    in_channels=1,\n","    classes=1,\n","    activation=ACTIVATION,\n",")\n","\n","model.to(DEVICE)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:45.292387Z","iopub.status.busy":"2023-01-30T17:33:45.289686Z","iopub.status.idle":"2023-01-30T17:33:45.304955Z","shell.execute_reply":"2023-01-30T17:33:45.303553Z","shell.execute_reply.started":"2023-01-30T17:33:45.292347Z"},"trusted":true},"outputs":[],"source":["train_dataset = Dataset(\n","    array_of_images, \n","    array_of_masks, \n","    augmentation=get_training_augmentation()\n",")\n","\n","# valid_dataset = Dataset(\n","#     X_test, \n","#     y_test\n","# )\n","\n","train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=8)\n","valid_loader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=8)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:45.307515Z","iopub.status.busy":"2023-01-30T17:33:45.306747Z","iopub.status.idle":"2023-01-30T17:33:45.320438Z","shell.execute_reply":"2023-01-30T17:33:45.319154Z","shell.execute_reply.started":"2023-01-30T17:33:45.307478Z"},"trusted":true},"outputs":[],"source":["loss = smp.utils.base.SumOfLosses(\n","    smp.utils.losses.DiceLoss(),\n","    smp.utils.losses.BCELoss()\n",")\n","\n","metrics = [\n","    smp.utils.metrics.IoU(threshold=0.5)\n","]\n","\n","optimizer = torch.optim.Adam([ \n","    dict(params=model.parameters(), lr=0.0001),\n","])"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:45.323059Z","iopub.status.busy":"2023-01-30T17:33:45.322288Z","iopub.status.idle":"2023-01-30T17:33:48.219134Z","shell.execute_reply":"2023-01-30T17:33:48.218139Z","shell.execute_reply.started":"2023-01-30T17:33:45.323022Z"},"trusted":true},"outputs":[],"source":["train_epoch = smp.utils.train.TrainEpoch(\n","    model, \n","    loss=loss, \n","    metrics=metrics, \n","    optimizer=optimizer,\n","    device=DEVICE,\n","    verbose=True,\n",")\n","\n","valid_epoch = smp.utils.train.ValidEpoch(\n","    model,\n","    loss=loss, \n","    metrics=metrics, \n","    device=DEVICE,\n","    verbose=True,\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train:   0%|          | 0/950 [00:00<?, ?it/s]"]}],"source":["train_logs = train_epoch.run(train_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-30T17:33:48.220908Z","iopub.status.busy":"2023-01-30T17:33:48.220537Z","iopub.status.idle":"2023-01-30T17:34:55.082678Z","shell.execute_reply":"2023-01-30T17:34:55.081175Z","shell.execute_reply.started":"2023-01-30T17:33:48.220872Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch: 0\n","train:   0%|          | 0/15 [00:00<?, ?it/s]"]}],"source":["max_score = 5\n","trash = 0\n","for i in range(0, 100):\n","    if trash > 6:\n","        break\n","    print('\\nEpoch: {}'.format(i))\n","    train_logs = train_epoch.run(train_loader)\n","    valid_logs = valid_epoch.run(valid_loader)\n","    \n","    # do something (save model, change lr, etc.)\n","    if max_score > valid_logs['dice_loss + bce_loss']:\n","        max_score = valid_logs['dice_loss + bce_loss']\n","        torch.save(model, './best_model.pth')\n","        trash = 0\n","        print('Model saved!')\n","    else:\n","        trash +=1\n","        \n","    if i == 25:\n","        optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr']*0.56\n","        print('Decrease decoder learning rate to 1e-5!')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-01-30T17:34:55.083991Z","iopub.status.idle":"2023-01-30T17:34:55.085031Z","shell.execute_reply":"2023-01-30T17:34:55.084778Z","shell.execute_reply.started":"2023-01-30T17:34:55.084751Z"},"trusted":true},"outputs":[],"source":["# tta_model_first = tta.SegmentationTTAWrapper(torch.load('best_model.pth'), tta.aliases.d4_transform(), merge_mode='mean')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"4af9a2159fab24886d4f91335261a63555b0395985130eb8d259fcbaf5c78d65"}}},"nbformat":4,"nbformat_minor":4}
