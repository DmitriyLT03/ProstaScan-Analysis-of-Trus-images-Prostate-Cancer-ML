{"cells":[{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import sys\n","import colorsys\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm_notebook\n","# from osgeo import gdal, gdalconst\n","# import gdal, gdalconst"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["import cv2\n","import argparse\n","import imutils\n","import numpy as np\n","from PIL import Image\n","from skimage import exposure"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import skimage.data as data\n","import skimage.segmentation as seg\n","import skimage.filters as filters\n","import skimage.draw as draw\n","import skimage.color as color\n","from PIL import Image"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["_StoreAction(option_strings=['-q', '--query'], dest='query', nargs=None, const=None, default=None, type=None, choices=None, required=True, help='Path to the query image', metavar=None)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# construct the argument parser and parse the arguments\n","ap = argparse.ArgumentParser()\n","ap.add_argument(\"-q\", \"--query\", required = True,help = \"Path to the query image\")"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["list_images = os.listdir('./data/Images_composit/Images_composit/8_ch')\n","list_masks = os.listdir('./data/mask/mask')"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["mean=[0.485, 0.456, 0.406]\n","std=[0.229, 0.224, 0.225]"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["['KVI_20180921_SCN8_UN87__KV4_20190622_SCN8_UN88.tif',\n"," 'KV6_20190609_SCN4_UN55__KV6_20200608_SCN3_UN56.tif',\n"," 'KV1_20180615_SCN9_UN39__KV3_20200522_SCN9_UN40.tif',\n"," 'KV1_20170527_SCN25_UN3__KV4_20190530_SCN25_UN4.tif',\n"," 'KV1_20180615_SCN6_UN43__KV5_20190625_SCN5_UN44.tif',\n"," 'KV1_20170922_SCN3_UN7__KV5_20190912_SCN3_UN8.tif',\n"," 'KV1_20180602_SCN16_UN29__KV5_20200901_SCN16_UN30.tif',\n"," 'KV1_20170922_SCN10_UN11__KV5_20190912_SCN10_UN12.tif',\n"," 'KV1_20180602_SCN14_UN27__KV5_20200901_SCN14_UN28.tif',\n"," 'KVI_20180606_SCN9_UN67__KV5_20190719_SCN9_UN68.tif',\n"," 'KV6_20190704_SCN2_UN57__KV5_20200521_SCN10_UN58.tif',\n"," 'KV1_20180501_SCN6_UN25__KV6_20190704_SCN2_UN26.tif',\n"," 'KV1_20180602_SCN17_UN31__KV5_20200901_SCN17_UN32.tif',\n"," 'KVI_20180618_SCN15_UN73__KV6_20190530_SCN8_UN74.tif',\n"," 'KVI_20180606_SCN2_UN59__KV5_20190805_SCN2_UN60.tif',\n"," 'KV1_20180615_SCN5_UN41__KVI_20190805_SCN5_UN42.tif',\n"," 'KV1_20170527_SCN18_UN1__KV5_20190908_SCN6_UN2.tif',\n"," 'KV1_20180615_SCN4_UN37__KV3_20200522_SCN4_UN38.tif',\n"," 'KVI_20180922_SCN3_UN91__KV1_20190804_SCN2_UN92.tif',\n"," 'KVI_20180606_SCN4_UN63__KV5_20190805_SCN4_UN64.tif',\n"," 'KV6_20190609_SCN3_UN53__KV6_20200608_SCN3_UN54.tif',\n"," 'KV1_20180603_SCN10_UN33__KV6_20190622_SCN9_UN34.tif',\n"," 'KV3_20180702_SCN2_UN49__KV4_20200829_SCN2_UN50.tif',\n"," 'KVI_20180920_SCN3_UN81__KV4_20190609_SCN3_UN82.tif',\n"," 'KVI_20180624_SCN11_UN77__KV3_20190830_SCN23_UN78.tif',\n"," 'KVI_20180921_SCN13_UN83__KV4_20190622_SCN13_UN84.tif',\n"," 'KVI_20180921_SCN9_UN89__KV4_20190622_SCN9_UN90.tif',\n"," 'KVI_20180606_SCN11_UN71__KV5_20190719_SCN11_UN72.tif',\n"," 'KVI_20180606_SCN10_UN69__KV5_20190719_SCN10_UN70.tif',\n"," 'KV4_20190629_SCN3_UN51__KV5_20200521_SCN3_UN52.tif',\n"," 'KVI_20180606_SCN6_UN65__KV5_20190805_SCN6_UN66.tif',\n"," 'KVI_20180618_SCN16_UN75__KV6_20190530_SCN9_UN76.tif',\n"," 'KV1_20180615_SCN1_UN35__KVI_20190805_SCN2_UN36.tif',\n"," 'KVI_20180606_SCN3_UN61__KV5_20190805_SCN3_UN62.tif',\n"," 'KV1_20170527_SCN26_UN5__KV4_20190530_SCN26_UN6.tif',\n"," 'KVI_20180805_SCN4_UN79__KV1_20190726_SCN5_UN80.tif',\n"," 'KV1_20170922_SCN5_UN17__KV5_20190912_SCN4_UN18.tif',\n"," 'KV3_20180702_SCN2_UN47__KV4_20200829_SCN1_UN48.tif',\n"," 'KV1_20180810_SCN10_UN45__KV5_20200914_SCN10_UN46.tif',\n"," 'KVI_20180921_SCN5_UN85__KV4_20190622_SCN5_UN86.tif',\n"," 'KVI_20180922_SCN4_UN93__KV1_20190804_SCN2_UN94.tif']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["list(set(list_images) - set(list_masks))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig=plt.figure(figsize=(20, 25))\n","two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{list(set(list_images) & set(list_masks))[-2]}', gdalconst.GA_ReadOnly)\n","channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,5)])\n","img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","fig.add_subplot(2, 2, 1)\n","plt.imshow(img_rgb_1)"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'gdal' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m fig\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m25\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m two_images \u001b[39m=\u001b[39m gdal\u001b[39m.\u001b[39mOpen(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(list_images)\u001b[39m \u001b[39m\u001b[39m&\u001b[39m\u001b[39m \u001b[39m\u001b[39mset\u001b[39m(list_masks))[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, gdalconst\u001b[39m.\u001b[39mGA_ReadOnly)\n\u001b[0;32m      3\u001b[0m channel_rgb1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack([np\u001b[39m.\u001b[39marray(two_images\u001b[39m.\u001b[39mGetRasterBand(i)\u001b[39m.\u001b[39mReadAsArray()) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m5\u001b[39m)])\n\u001b[0;32m      4\u001b[0m img_rgb_1 \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39mmoveaxis(channel_rgb1, \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m1024\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'gdal' is not defined"]},{"data":{"text/plain":["<Figure size 2000x2500 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig=plt.figure(figsize=(20, 25))\n","two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{list(set(list_images) & set(list_masks))[-2]}', gdalconst.GA_ReadOnly)\n","channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,5)])\n","img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","fig.add_subplot(2, 2, 1)\n","plt.imshow(img_rgb_1)#[1100:1400,1500:2000]\n","\n","channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(5,9)])\n","img_rgb_2 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","fig.add_subplot(2, 2, 2)\n","plt.imshow(img_rgb_2)\n","\n","mask = gdal.Open(f'../input/roscosmos-rucode/mask/mask/{list(set(list_images) & set(list_masks))[-2]}', gdalconst.GA_ReadOnly)\n","fig.add_subplot(2, 2, 3)\n","plt.imshow((img_rgb_2-img_rgb_1))\n","\n","fig.add_subplot(2, 2, 4)\n","plt.imshow(img_rgb_2[:,:,2]+ mask.GetRasterBand(1).ReadAsArray())\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def decode_mask(mask):\n","    pixels = mask.T.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv('../input/roscosmos-rucode/sample_submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["array_of_threshold = [0.14,0.02,0.1,1e-09,0.55,0.08,0.05,0.4,0.36,0.0001,0.07,0.05,1e-05,1e-08,0.22,0.03,0.1,0.0,0.35,0.4,0.06,0.001,0.08,0.08,0.09,0.06,0.5,0.1,0.001,0.15,0.0,0.08,0.28,0.35,0.0,0.08,0.52,0.1,0.1,0.0,0.0]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list_names_images = ['KV1_20170922_SCN10_UN11__KV5_20190912_SCN10_UN12.tif',\n"," 'KVI_20180606_SCN2_UN59__KV5_20190805_SCN2_UN60.tif',\n"," 'KVI_20180922_SCN4_UN93__KV1_20190804_SCN2_UN94.tif',\n"," 'KVI_20180922_SCN3_UN91__KV1_20190804_SCN2_UN92.tif',\n"," 'KV1_20180615_SCN5_UN41__KVI_20190805_SCN5_UN42.tif',\n"," 'KVI_20180606_SCN3_UN61__KV5_20190805_SCN3_UN62.tif',\n"," 'KVI_20180618_SCN15_UN73__KV6_20190530_SCN8_UN74.tif',\n"," 'KV1_20180615_SCN4_UN37__KV3_20200522_SCN4_UN38.tif',\n"," 'KV1_20180615_SCN6_UN43__KV5_20190625_SCN5_UN44.tif',\n"," 'KVI_20180606_SCN6_UN65__KV5_20190805_SCN6_UN66.tif',\n"," 'KV1_20170527_SCN18_UN1__KV5_20190908_SCN6_UN2.tif',\n"," 'KV6_20190609_SCN4_UN55__KV6_20200608_SCN3_UN56.tif',\n"," 'KVI_20180921_SCN9_UN89__KV4_20190622_SCN9_UN90.tif',\n"," 'KVI_20180921_SCN8_UN87__KV4_20190622_SCN8_UN88.tif',\n"," 'KV1_20170922_SCN3_UN7__KV5_20190912_SCN3_UN8.tif',\n"," 'KV6_20190609_SCN3_UN53__KV6_20200608_SCN3_UN54.tif',\n"," 'KVI_20180618_SCN16_UN75__KV6_20190530_SCN9_UN76.tif',\n"," 'KV1_20180810_SCN10_UN45__KV5_20200914_SCN10_UN46.tif',\n"," 'KV4_20190629_SCN3_UN51__KV5_20200521_SCN3_UN52.tif',\n"," 'KV1_20180615_SCN9_UN39__KV3_20200522_SCN9_UN40.tif',\n"," 'KV1_20180602_SCN17_UN31__KV5_20200901_SCN17_UN32.tif',\n"," 'KVI_20180920_SCN3_UN81__KV4_20190609_SCN3_UN82.tif',\n"," 'KV1_20180602_SCN16_UN29__KV5_20200901_SCN16_UN30.tif',\n"," 'KVI_20180921_SCN5_UN85__KV4_20190622_SCN5_UN86.tif',\n"," 'KV6_20190704_SCN2_UN57__KV5_20200521_SCN10_UN58.tif',\n"," 'KVI_20180606_SCN4_UN63__KV5_20190805_SCN4_UN64.tif',\n"," 'KV1_20170527_SCN25_UN3__KV4_20190530_SCN25_UN4.tif',\n"," 'KV1_20180603_SCN10_UN33__KV6_20190622_SCN9_UN34.tif',\n"," 'KVI_20180606_SCN9_UN67__KV5_20190719_SCN9_UN68.tif',\n"," 'KVI_20180805_SCN4_UN79__KV1_20190726_SCN5_UN80.tif',\n"," 'KV3_20180702_SCN2_UN49__KV4_20200829_SCN2_UN50.tif',\n"," 'KV1_20180501_SCN6_UN25__KV6_20190704_SCN2_UN26.tif',\n"," 'KV1_20170922_SCN5_UN17__KV5_20190912_SCN4_UN18.tif',\n"," 'KV1_20170527_SCN26_UN5__KV4_20190530_SCN26_UN6.tif',\n"," 'KVI_20180606_SCN10_UN69__KV5_20190719_SCN10_UN70.tif',\n"," 'KVI_20180921_SCN13_UN83__KV4_20190622_SCN13_UN84.tif',\n"," 'KV1_20180615_SCN1_UN35__KVI_20190805_SCN2_UN36.tif',\n"," 'KV1_20180602_SCN14_UN27__KV5_20200901_SCN14_UN28.tif',\n"," 'KVI_20180624_SCN11_UN77__KV3_20190830_SCN23_UN78.tif',\n"," 'KVI_20180606_SCN11_UN71__KV5_20190719_SCN11_UN72.tif',\n"," 'KV3_20180702_SCN2_UN47__KV4_20200829_SCN1_UN48.tif']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["index = 0\n","for i, name in enumerate(list_names_images):\n","    two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{name}', gdalconst.GA_ReadOnly)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,4)])\n","    img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(5,8)])\n","    img_rgb_2 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    if index >= len(array_of_threshold):\n","        print(i+1)\n","        p = input(\"Введите порог: \")\n","        while p!='stop':\n","            fig=plt.figure(figsize=(10, 15))\n","            p = float(p)\n","            cv2.imwrite('image.png', ((img_rgb_2-img_rgb_1)*256).astype(int))\n","            image = cv2.imread('image.png')\n","            image = imutils.resize(image, height = 300)\n","            gray = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","            gray = cv2.bilateralFilter(gray, 14, 15, 2)\n","            edged = cv2.Canny(gray[:,:,2], 60, 150)\n","            fig.add_subplot(1, 2, 1)\n","            plt.imshow(np.array([[[255,255,255] if edged[i,j] == 255 else pixel for j,pixel in enumerate(line)] for i, line in enumerate(image)]))\n","            img_result = ((img_rgb_2-img_rgb_1)[:,:,0]>p).astype(int)\n","            fig.add_subplot(1, 2, 2)\n","            plt.imshow(img_result)\n","            df.loc[df.Id == name[:-4], 'mask'] = decode_mask(img_result)\n","            plt.show()\n","            p_real = p\n","            p = input(\"Введите порог: \")\n","        array_of_threshold.append(p_real)\n","        index+=1\n","    else:\n","        fig=plt.figure(figsize=(10, 15))\n","        cv2.imwrite('image.png', ((img_rgb_2-img_rgb_1)*256).astype(int))\n","        image = cv2.imread('image.png')\n","        image = imutils.resize(image, height = 300)\n","        gray = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        gray = cv2.bilateralFilter(gray, 14, 15, 2)\n","        edged = cv2.Canny(gray[:,:,2], 60, 150)\n","        fig.add_subplot(1, 2, 1)\n","        plt.imshow(np.array([[[255,255,255] if edged[i,j] == 255 else pixel for j,pixel in enumerate(line)] for i, line in enumerate(image)]))\n","        img_result = ((img_rgb_2-img_rgb_1)[:,:,0]>array_of_threshold[index]).astype(int)\n","        fig.add_subplot(1, 2, 2)\n","        plt.imshow(img_result)\n","        index+=1\n","        df.loc[df.Id == name[:-4], 'mask'] = decode_mask(img_result)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image = ((img_rgb_2 - img_rgb_2.mean())/img_rgb_2.std()-(img_rgb_1 - img_rgb_1.mean())/img_rgb_1.std())*256\n","cv2.imwrite('image.png', (image).astype(int))\n","image = cv2.imread('image.png').astype('uint8')\n","gray = cv2.bilateralFilter(image, 37, 25, 28)\n","kernel = np.ones((8,8),np.float32)/25\n","dst = cv2.filter2D(gray[:,:,0],-1,kernel)\n","dst = (dst/256 > 0.65).astype('uint8')\n","edged = cv2.Canny(dst, 3, 5)\n","img = edged.copy()\n","contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","cv2.drawContours( img, contours, -1, (255,0,0), -1, cv2.LINE_AA, hierarchy, 1)\n","contours, hierarchy = cv2.findContours(gray[:,:,0].copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","cv2.drawContours( img, contours, -1, (0,0,0), 3, cv2.LINE_AA, hierarchy, 1)\n","contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","cv2.drawContours(img, contours, -1, (255,0,0), -1, cv2.LINE_AA, hierarchy, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image = np.array([[pixel.max() for pixel in line] for line in image])/256\n","max_dice = 0\n","gt = np.array([[1 if a == 1 else 0 for a in line] for line in dst])\n","for p in tqdm_notebook(np.arange(0,1,0.001)):\n","    seg = (image>p).astype(int)\n","    curr_dice = np.sum(seg[gt==1])*2.0 / (np.sum(seg) + np.sum(gt))\n","    if curr_dice>max_dice:\n","        real_p = p\n","        max_dice = curr_dice\n","print(max_dice, real_p)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image = ((img_rgb_2 - img_rgb_2.mean())/img_rgb_2.std()-(img_rgb_1 - img_rgb_1.mean())/img_rgb_1.std())*256\n","# image = np.array([[pixel.max() for pixel in line] for line in image])\n","# cv2.imwrite('image.png', (image*256).astype(int))\n","# img = Image.open('image.png').convert('LA')\n","# img.save('image.png')\n","# image = cv2.imread('image.png', cv2.IMREAD_GRAYSCALE)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mask = gdal.Open(f'../input/roscosmos-rucode/mask/mask/{list(set(list_images) & set(list_masks))[0]}', gdalconst.GA_ReadOnly)\n","gt = mask.GetRasterBand(1).ReadAsArray()\n","seg = (image>real_p).astype(int)#np.array([[1 if a == 1 else 0 for a in line] for line in dst])\n","score = np.sum(seg[gt==1])*2.0 / (np.sum(seg) + np.sum(gt))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img1 = (img_rgb_1 - np.mean(img_rgb_1))/np.std(img_rgb_1)\n","img2 = (img_rgb_2 - np.mean(img_rgb_2))/np.std(img_rgb_2)\n","\n","img1_gray = 0.299*img1[:,:,0] + 0.587*img1[:,:,1] + 0.114*img1[:,:,2]\n","img2_gray = 0.299*img2[:,:,0] + 0.587*img2[:,:,1] + 0.114*img2[:,:,2]\n","\n","img1_new_gray = img1_gray*0.8+img1[:,:,3]*0.2\n","img2_new_gray = img2_gray*0.8+img2[:,:,3]*0.2\n","\n","image = (img2_new_gray - img1_new_gray)#*255\n","image = (image - np.mean(image))/np.std(image)\n","# image = image.astype('uint8')\n","# gray = cv2.bilateralFilter(image, 37, 25, 28)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig,ax = plt.subplots(figsize = (10,15))\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig,ax = plt.subplots(figsize = (10,15))\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig=plt.figure(figsize=(20, 25))\n","# new_image = np.array([[pixel if pixel/256>0.12 else 0 for pixel in line] for line in image]).astype('uint8')\n","fig.add_subplot(1, 2, 1)\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig=plt.figure(figsize=(20, 25))\n","# new_image = np.array([[pixel if pixel/256>0.12 else 0 for pixel in line] for line in image]).astype('uint8')\n","fig.add_subplot(1, 2, 1)\n","plt.imshow(image)\n","# fig.add_subplot(1, 2, 2)\n","# plt.imshow((image/256+mask.GetRasterBand(1).ReadAsArray()))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gray = cv2.GaussianBlur(image.astype('uint8'),(5,5),sigmaX=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# gray = cv2.bilateralFilter(new_image, 37, 25, 28)\n","#gray = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","gray = cv2.bilateralFilter(image, 37, 25, 28)\n","kernel = np.ones((8,8),np.float32)/25\n","dst = cv2.filter2D(gray[:,:,0],-1,kernel)\n","dst = (dst/256 > 0.65).astype('uint8')\n","edged = cv2.Canny(dst, 3, 5)\n","fig=plt.figure(figsize=(10, 15))\n","plt.imshow(edged)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["scores = []\n","for i, name in enumerate(list(set(list_images) & set(list_masks))):\n","    two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{name}', gdalconst.GA_ReadOnly)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,4)])\n","    img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(5,8)])\n","    img_rgb_2 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    image = ((img_rgb_2 - img_rgb_2.mean())/img_rgb_2.std()-(img_rgb_1 - img_rgb_1.mean())/img_rgb_1.std())*256\n","    cv2.imwrite('image.png', (image).astype(int))\n","    image = cv2.imread('image.png').astype('uint8')\n","    gray = cv2.bilateralFilter(image, 37, 25, 28)\n","    kernel = np.ones((8,8),np.float32)/25\n","    dst = cv2.filter2D(gray[:,:,0],-1,kernel)\n","    dst = (dst/256 > 0.65).astype('uint8')\n","#     edged = cv2.Canny(dst, 3, 5)\n","#     img = edged.copy()\n","#     contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","#     cv2.drawContours( img, contours, -1, (255,0,0), -1, cv2.LINE_AA, hierarchy, 1)\n","#     contours, hierarchy = cv2.findContours(gray[:,:,0].copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","#     cv2.drawContours( img, contours, -1, (0,0,0), 3, cv2.LINE_AA, hierarchy, 1)\n","#     contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","#     cv2.drawContours(img, contours, -1, (255,0,0), -1, cv2.LINE_AA, hierarchy, 1)\n","        #img = imutils.resize(img, height = image_height)\n","    image = np.array([[pixel.max() for pixel in line] for line in image])/256\n","    max_dice = 0\n","    gt = np.array([[1 if a == 1 else 0 for a in line] for line in dst])\n","    for p in tqdm_notebook(np.arange(0,1,0.001)):\n","        seg = (image>p).astype(int)\n","        curr_dice = np.sum(seg[gt==1])*2.0 / (np.sum(seg) + np.sum(gt))\n","        if curr_dice>max_dice:\n","            real_p = p\n","            max_dice = curr_dice\n","    #evaluation\n","    mask = gdal.Open(f'../input/roscosmos-rucode/mask/mask/{name}', gdalconst.GA_ReadOnly)\n","    gt = mask.GetRasterBand(1).ReadAsArray()\n","    seg = (image>real_p).astype(int)#np.array([[1 if a == 1 else 0 for a in line] for line in dst])\n","    score = np.sum(seg[gt==1])*2.0 / (np.sum(seg) + np.sum(gt))\n","    scores.append(score)\n","    print(\"Dice = \",score)\n","    fig=plt.figure(figsize=(10, 15))\n","    plt.imshow(seg)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["np.mean(scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list_threashold = []\n","for i, name in enumerate(list_names_images):\n","    two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{name}', gdalconst.GA_ReadOnly)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,4)])\n","    img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(5,8)])\n","    img_rgb_2 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    image = ((img_rgb_2 - img_rgb_2.mean())/img_rgb_2.std()-(img_rgb_1 - img_rgb_1.mean())/img_rgb_1.std())*256\n","    cv2.imwrite('image.png', (image).astype(int))\n","    image = cv2.imread('image.png').astype('uint8')\n","    gray = cv2.bilateralFilter(image, 37, 25, 28)\n","    kernel = np.ones((8,8),np.float32)/25\n","    dst = cv2.filter2D(gray[:,:,0],-1,kernel)\n","    dst = (dst/256 > 0.65).astype('uint8')\n","#     edged = cv2.Canny(dst, 3, 5)\n","#     img = edged.copy()\n","#     contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","#     cv2.drawContours( img, contours, -1, (255,0,0), -1, cv2.LINE_AA, hierarchy, 1)\n","#     contours, hierarchy = cv2.findContours(gray[:,:,0].copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","#     cv2.drawContours( img, contours, -1, (0,0,0), 3, cv2.LINE_AA, hierarchy, 1)\n","#     contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","#     cv2.drawContours(img, contours, -1, (255,0,0), -1, cv2.LINE_AA, hierarchy, 1)\n","        #img = imutils.resize(img, height = image_height)\n","    image = np.array([[pixel.max() for pixel in line] for line in image])/256\n","    max_dice = 0\n","    gt = np.array([[1 if a == 1 else 0 for a in line] for line in dst])\n","    for p in tqdm_notebook(np.arange(0,1,0.001)):\n","        seg = (image>p).astype(int)\n","        curr_dice = np.sum(seg[gt==1])*2.0 / (np.sum(seg) + np.sum(gt))\n","        if curr_dice>max_dice:\n","            real_p = p\n","            max_dice = curr_dice\n","    \n","    seg = (image>real_p).astype(int)#np.array([[1 if a == 1 else 0 for a in line] for line in dst])\n","    list_threashold.append(real_p)\n","    \n","    df.loc[df.Id == name[:-4], 'mask'] = decode_mask(seg)\n","    fig=plt.figure(figsize=(10, 15))\n","    plt.imshow(seg)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list(zip(list_threashold, array_of_threshold))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list_threashold[-15] = array_of_threshold[-15]\n","list_threashold[-8] = array_of_threshold[-8]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["index = 0\n","for i, name in enumerate(list_names_images):\n","    two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{name}', gdalconst.GA_ReadOnly)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,4)])\n","    img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(5,8)])\n","    img_rgb_2 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    fig=plt.figure(figsize=(10, 15))\n","    img_result = ((img_rgb_2-img_rgb_1)[:,:,0]>list_threashold[index]).astype(int)\n","    plt.imshow(img_result)\n","    index+=1\n","    df.loc[df.Id == name[:-4], 'mask'] = decode_mask(img_result)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.to_csv('sabmission.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Make data dirs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Add new folders\n","#\n","os.mkdir(\"./train\")\n","os.mkdir(\"./masks\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Making dataset files\n","#\n","array_of_images = []\n","array_of_masks = []\n","for name in list(set(list_images) & set(list_masks)):\n","    two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{name}', gdalconst.GA_ReadOnly)\n","    \n","    #Preprocess and grayscale image\n","    \n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,5)])\n","    img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(5,9)])\n","    img_rgb_2 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    \n","    img1 = (img_rgb_1 - np.mean(img_rgb_1))/np.std(img_rgb_1)\n","    img2 = (img_rgb_2 - np.mean(img_rgb_2))/np.std(img_rgb_2)\n","\n","    img1_gray = 0.299*img1[:,:,0] + 0.587*img1[:,:,1] + 0.114*img1[:,:,2]\n","    img2_gray = 0.299*img2[:,:,0] + 0.587*img2[:,:,1] + 0.114*img2[:,:,2]\n","\n","    img1_new_gray = img1_gray*0.8+img1[:,:,3]*0.2\n","    img2_new_gray = img2_gray*0.8+img2[:,:,3]*0.2\n","\n","    image = (img2_new_gray - img1_new_gray)#*255\n","    image = (image - np.mean(image))/np.std(image)\n","    \n","    mask = gdal.Open(f'../input/roscosmos-rucode/mask/mask/{name}', gdalconst.GA_ReadOnly)\n","    \n","    #Extract our images\n","    mask = mask.GetRasterBand(1).ReadAsArray()\n","    array_of_images.append(image)\n","    array_of_masks.append(mask)\n","    \n","#     #Cropp image to plenty of images with normal ground truth and save it to dataset folders\n","#     for i in tqdm_notebook(range(256, image.shape[0], 256)):\n","#         for j in range(256, image.shape[1], 256):\n","#             if mask[i-256:i, j-256:j].sum()>0:\n","#                 cv2.imwrite(f'./train/{name[:-4]}_{i}_{j}.png', image[i-256:i, j-256:j])\n","#                 cv2.imwrite(f'./masks/{name[:-4]}_{i}_{j}.png', mask[i-256:i, j-256:j]*255)\n","#                 array_of_images.append(image[i-256:i, j-256:j])\n","#                 array_of_masks.append(mask[i-256:i, j-256:j])\n","#     os.remove(f'./train/{name[:-4]}.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["array_of_images*=100\n","array_of_masks*=100"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["# Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import albumentations as albu"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["IMG_SIZE = 128"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# def get_training_augmentation():\n","#     train_transform = [\n","\n","#         albu.HorizontalFlip(p=0.5),\n","\n","#         albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n","\n","#         albu.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n","#         albu.RandomCrop(height=320, width=320, always_apply=True),\n","\n","#         albu.IAAAdditiveGaussianNoise(p=0.2),\n","#         albu.IAAPerspective(p=0.5),\n","\n","#         albu.OneOf(\n","#             [\n","#                 albu.CLAHE(p=1),\n","#                 albu.RandomBrightness(p=1),\n","#                 albu.RandomGamma(p=1),\n","#             ],\n","#             p=0.9,\n","#         ),\n","\n","#         albu.OneOf(\n","#             [\n","#                 albu.IAASharpen(p=1),\n","#                 albu.Blur(blur_limit=3, p=1),\n","#                 albu.MotionBlur(blur_limit=3, p=1),\n","#             ],\n","#             p=0.9,\n","#         ),\n","\n","#         albu.OneOf(\n","#             [\n","#                 albu.RandomContrast(p=1),\n","#                 albu.HueSaturationValue(p=1),\n","#             ],\n","#             p=0.9,\n","#         ),\n","#     ]\n","    # return albu.Compose(train_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_training_augmentation():\n","    train_transform = [\n","        \n","        albu.RandomCrop(width = IMG_SIZE, height = IMG_SIZE),\n","        albu.RandomRotate90(),\n","        albu.Flip(p=0.5),\n","#         albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n","    ]\n","    return albu.Compose(train_transform)"]},{"cell_type":"markdown","metadata":{},"source":["# Data loader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Dataset(BaseDataset):\n","    def __init__(\n","            self, \n","            images, \n","            masks, \n","            augmentation=None\n","    ):\n","        self.images = images\n","        self.masks = masks\n","        self.augmentation = augmentation\n","    \n","    def __getitem__(self, i):\n","        image = self.images[i]\n","        mask = self.masks[i]\n","        # apply augmentations\n","        flag = np.random.rand() > 0.3\n","        \n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            img, small_mask = sample['image'], sample['mask']\n","            while small_mask.sum() == 0 and flag:\n","                sample = self.augmentation(image=image, mask=mask)\n","                img, small_mask = sample['image'], sample['mask']\n","        \n","        \n","        return torch.tensor(np.array([img]), dtype = torch.float), torch.tensor(np.array([small_mask]), dtype = torch.float)\n","        \n","    def __len__(self):\n","        return len(self.images)"]},{"cell_type":"markdown","metadata":{},"source":["# Create model and train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","import segmentation_models_pytorch as smp"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ENCODER = 'resnet34'\n","ENCODER_WEIGHTS = 'imagenet'\n","ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n","DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu') \n","\n","# create segmentation model with pretrained encoder\n","model = smp.UnetPlusPlus(\n","    encoder_name=ENCODER, \n","    encoder_weights=ENCODER_WEIGHTS,\n","    in_channels=1,\n","    classes=1,\n","    activation=ACTIVATION,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = Dataset(\n","    array_of_images, \n","    array_of_masks, \n","    augmentation=get_training_augmentation()\n",")\n","\n","# valid_dataset = Dataset(\n","#     X_test, \n","#     y_test\n","# )\n","\n","train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=12)\n","valid_loader = DataLoader(train_dataset, batch_size=20, shuffle=False, num_workers=12)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["loss = smp.utils.base.SumOfLosses(\n","    smp.utils.losses.DiceLoss(),\n","    smp.utils.losses.BCELoss()\n",")\n","\n","metrics = [\n","    smp.utils.metrics.IoU(threshold=0.5)\n","]\n","\n","optimizer = torch.optim.Adam([ \n","    dict(params=model.parameters(), lr=0.0001),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_epoch = smp.utils.train.TrainEpoch(\n","    model, \n","    loss=loss, \n","    metrics=metrics, \n","    optimizer=optimizer,\n","    device=DEVICE,\n","    verbose=True,\n",")\n","\n","valid_epoch = smp.utils.train.ValidEpoch(\n","    model,\n","    loss=loss, \n","    metrics=metrics, \n","    device=DEVICE,\n","    verbose=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["max_score = 5\n","trash = 0\n","for i in range(0, 100):\n","    if trash > 6:\n","        break\n","    print('\\nEpoch: {}'.format(i))\n","    train_logs = train_epoch.run(train_loader)\n","    valid_logs = valid_epoch.run(valid_loader)\n","    \n","    # do something (save model, change lr, etc.)\n","    if max_score > valid_logs['dice_loss + bce_loss']:\n","        max_score = valid_logs['dice_loss + bce_loss']\n","        torch.save(model, './best_model.pth')\n","        trash = 0\n","        print('Model saved!')\n","    else:\n","        trash +=1\n","        \n","    if i == 25:\n","        optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr']*0.56\n","        print('Decrease decoder learning rate to 1e-5!')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import ttach as tta"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["best_model = torch.load('./best_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tta_model = tta.SegmentationTTAWrapper(best_model, tta.aliases.d4_transform(), merge_mode='mean')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["scores = []\n","for name in list(set(list_images) & set(list_masks)):\n","    two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{name}', gdalconst.GA_ReadOnly)\n","    \n","    #Preprocess and grayscale image\n","    \n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,5)])\n","    img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(5,9)])\n","    img_rgb_2 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    \n","    img1 = (img_rgb_1 - np.mean(img_rgb_1))/np.std(img_rgb_1)\n","    img2 = (img_rgb_2 - np.mean(img_rgb_2))/np.std(img_rgb_2)\n","\n","    img1_gray = 0.299*img1[:,:,0] + 0.587*img1[:,:,1] + 0.114*img1[:,:,2]\n","    img2_gray = 0.299*img2[:,:,0] + 0.587*img2[:,:,1] + 0.114*img2[:,:,2]\n","\n","    img1_new_gray = img1_gray*0.8+img1[:,:,3]*0.2\n","    img2_new_gray = img2_gray*0.8+img2[:,:,3]*0.2\n","\n","    image = (img2_new_gray - img1_new_gray)#*255\n","    image = (image - np.mean(image))/np.std(image)\n","    \n","    new_shape = (\n","        int(np.ceil(image.shape[0] / IMG_SIZE) * IMG_SIZE), \n","        int(np.ceil(image.shape[1] / IMG_SIZE) * IMG_SIZE)\n","    )\n","    IMG_new = np.full(new_shape, 0)\n","    res_mask = np.zeros(new_shape)\n","    \n","    IMG_new[:image.shape[0], :image.shape[1]] = image\n","    \n","    for i in range(0, new_shape[0], IMG_SIZE):\n","        for j in range(0, new_shape[1], IMG_SIZE):\n","            x_tensor = torch.Tensor(np.array([\n","                    IMG_new[i:i+IMG_SIZE, j:j+IMG_SIZE]\n","            ])).to(DEVICE).unsqueeze(0)\n","            pr_mask = tta_model(x_tensor)\n","            pr_mask = (pr_mask.squeeze().detach().cpu().numpy().round())\n","            \n","            res_mask[i:i+IMG_SIZE, j:j+IMG_SIZE] = pr_mask\n","       \n","    res_mask = res_mask[:image.shape[0], :image.shape[1]]\n","    mask = gdal.Open(f'../input/roscosmos-rucode/mask/mask/{name}', gdalconst.GA_ReadOnly)\n","    gt = mask.GetRasterBand(1).ReadAsArray()\n","    seg = res_mask\n","    score = np.sum(seg[gt==1])*2.0 / (np.sum(seg) + np.sum(gt))\n","    scores.append(score)\n","    print(\"Dice = \",score)\n","    fig=plt.figure(figsize=(10, 15))\n","    plt.imshow(res_mask); plt.show()\n","    # res_mask = NDTS(NIR1, NIR2)\n","    # res_mask = NVDI(NIR1, NIR2, RED1, RED2)\n","    # res_mask = find_PCAKmeans(NIR1, NIR2)\n","    # res_mask = all_ones(NIR1, NIR2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["np.mean(scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["res = []\n","for name in list_names_images:\n","    two_images = gdal.Open(f'../input/roscosmos-rucode/Images_composit/Images_composit/8_ch/{name}', gdalconst.GA_ReadOnly)\n","    \n","    #Preprocess and grayscale image\n","    \n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(1,5)])\n","    img_rgb_1 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    channel_rgb1 = np.stack([np.array(two_images.GetRasterBand(i).ReadAsArray()) for i in range(5,9)])\n","    img_rgb_2 = (np.moveaxis(channel_rgb1, 0, -1)/1024)\n","    \n","    img1 = (img_rgb_1 - np.mean(img_rgb_1))/np.std(img_rgb_1)\n","    img2 = (img_rgb_2 - np.mean(img_rgb_2))/np.std(img_rgb_2)\n","\n","    img1_gray = 0.299*img1[:,:,0] + 0.587*img1[:,:,1] + 0.114*img1[:,:,2]\n","    img2_gray = 0.299*img2[:,:,0] + 0.587*img2[:,:,1] + 0.114*img2[:,:,2]\n","\n","    img1_new_gray = img1_gray*0.8+img1[:,:,3]*0.2\n","    img2_new_gray = img2_gray*0.8+img2[:,:,3]*0.2\n","\n","    image = (img2_new_gray - img1_new_gray)#*255\n","    image = (image - np.mean(image))/np.std(image)\n","    \n","    new_shape = (\n","        int(np.ceil(image.shape[0] / IMG_SIZE) * IMG_SIZE), \n","        int(np.ceil(image.shape[1] / IMG_SIZE) * IMG_SIZE)\n","    )\n","    IMG_new = np.full(new_shape, 0)\n","    res_mask = np.zeros(new_shape)\n","    \n","    IMG_new[:image.shape[0], :image.shape[1]] = image\n","    \n","    for i in range(0, new_shape[0], IMG_SIZE):\n","        for j in range(0, new_shape[1], IMG_SIZE):\n","            x_tensor = torch.Tensor(np.array([\n","                    IMG_new[i:i+IMG_SIZE, j:j+IMG_SIZE]\n","            ])).to(DEVICE).unsqueeze(0)\n","            pr_mask = tta_model(x_tensor)\n","            pr_mask = (pr_mask.squeeze().detach().cpu().numpy().round())\n","            \n","            res_mask[i:i+IMG_SIZE, j:j+IMG_SIZE] = pr_mask\n","       \n","    res_mask = res_mask[:image.shape[0], :image.shape[1]]\n","    fig=plt.figure(figsize=(20, 25))\n","    fig.add_subplot(1, 3, 1)\n","    plt.imshow(res_mask)\n","    fig.add_subplot(1, 3, 2)\n","    plt.imshow(image)\n","    fig.add_subplot(1, 3, 3)\n","    plt.imshow(image+res_mask*255)\n","    \n","    plt.show()\n","    # res_mask = NDTS(NIR1, NIR2)\n","    # res_mask = NVDI(NIR1, NIR2, RED1, RED2)\n","    # res_mask = find_PCAKmeans(NIR1, NIR2)\n","    # res_mask = all_ones(NIR1, NIR2)\n","    df.loc[df.Id == name[:-4], 'mask'] = decode_mask(res_mask)\n","    res.append(decode_mask(res_mask))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i, name in enumerate(list_names_images):\n","    df.loc[df.Id == name[:-4], 'mask'] = res[i]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.to_csv('sabmission.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"env_trus","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"4af9a2159fab24886d4f91335261a63555b0395985130eb8d259fcbaf5c78d65"}}},"nbformat":4,"nbformat_minor":4}
